{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fe0b572",
   "metadata": {},
   "source": [
    "\n",
    "# üß™ Midterm Practice ‚Äî Data Analysis & Probability Distributions\n",
    "\n",
    "**N·ªôi dung:**  \n",
    "1) ƒê·ªçc d·ªØ li·ªáu t·ª´ file, t√≠nh c√°c ƒë·∫∑c tr∆∞ng, tr·ª±c quan h√≥a d·ªØ li·ªáu.  \n",
    "2) T√≠nh x√°c su·∫•t v√† ph√¢n v·ªã c·ªßa ph√¢n ph·ªëi **Nh·ªã th·ª©c (Binomial), Poisson, Chu·∫©n (Normal)**.  \n",
    "3) Kho·∫£ng tin c·∫≠y cho **t·ª∑ l·ªá**.\n",
    "\n",
    "> G·ª£i √Ω: Notebook n√†y **t·ª± ch·∫°y ƒë∆∞·ª£c** v·ªõi c√°c dataset b·∫°n ƒë√£ ƒë∆∞a:  \n",
    "`03_FRESH15.xls`, `02_BODYTEMP.xls`, `06_BEARS.xls`, `13_VOLTAGE.xls`, `18_M&M.xls`, `19_SCREWS.xls`, `24_FICO.xls`, `gapminder_tidy.csv`, `diamonds.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1e5a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Chu·∫©n b·ªã th∆∞ vi·ªán\n",
    "import os, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# L∆∞u √Ω cho ph·∫ßn v·∫Ω: d√πng matplotlib, m·ªói bi·ªÉu ƒë·ªì 1 figure ri√™ng, kh√¥ng set m√†u c·ª• th·ªÉ.\n",
    "print(\"Libs OK\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9fe623",
   "metadata": {},
   "source": [
    "\n",
    "## 0) Ch·ªçn dataset ƒë·ªÉ luy·ªán\n",
    "- ƒê·ªïi ƒë∆∞·ªùng d·∫´n `DATA_PATH` cho dataset b·∫°n mu·ªën l√†m.\n",
    "- Notebook c√≥ ki·ªÉm tra c·ªôt ƒë·ªÉ t·ª± g·ª£i √Ω b√†i t·∫≠p ph√π h·ª£p.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d79e0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Li·ªát k√™ file c√≥ s·∫µn trong /mnt/data (n·∫øu b·∫°n ƒëang ch·∫°y m√¥i tr∆∞·ªùng n√†y)\n",
    "candidates = [\n",
    "    \"/mnt/data/03_FRESH15.xls\",\n",
    "    \"/mnt/data/02_BODYTEMP.xls\",\n",
    "    \"/mnt/data/06_BEARS.xls\",\n",
    "    \"/mnt/data/13_VOLTAGE.xls\",\n",
    "    \"/mnt/data/18_M&M.xls\",\n",
    "    \"/mnt/data/19_SCREWS.xls\",\n",
    "    \"/mnt/data/24_FICO.xls\",\n",
    "    \"/mnt/data/gapminder_tidy.csv\",\n",
    "    \"/mnt/data/diamonds.csv\",\n",
    "]\n",
    "\n",
    "existing = [p for p in candidates if os.path.exists(p)]\n",
    "existing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d563348b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Ch·ªçn 1 file t·ª´ danh s√°ch 'existing' ·ªü cell tr√™n ho·∫∑c ƒëi·ªÅn ƒë∆∞·ªùng d·∫´n c·ªßa b·∫°n\n",
    "DATA_PATH = existing[0] if existing else \"/mnt/data/03_FRESH15.xls\"\n",
    "DATA_PATH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ace2ec8",
   "metadata": {},
   "source": [
    "\n",
    "## 1) ƒê·ªçc d·ªØ li·ªáu & kh√°m ph√° s∆° b·ªô\n",
    "**Y√™u c·∫ßu:**\n",
    "- ƒê·ªçc file\n",
    "- In `head(5)`, `shape`, `dtypes`\n",
    "- Ki·ªÉm tra thi·∫øu d·ªØ li·ªáu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd04c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ƒê·ªçc d·ªØ li·ªáu linh ho·∫°t theo ph·∫ßn m·ªü r·ªông\n",
    "ext = os.path.splitext(DATA_PATH)[1].lower()\n",
    "if ext in [\".xls\", \".xlsx\"]:\n",
    "    try:\n",
    "        df = pd.read_excel(DATA_PATH)\n",
    "    except Exception:\n",
    "        try:\n",
    "            df = pd.read_excel(DATA_PATH, engine=\"xlrd\")\n",
    "        except Exception:\n",
    "            df = pd.read_excel(DATA_PATH, engine=\"openpyxl\")\n",
    "elif ext in [\".csv\", \".txt\"]:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "else:\n",
    "    # last resort\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head())\n",
    "print(\"\\nDtypes:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nMissing per column:\")\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976e8209",
   "metadata": {},
   "source": [
    "\n",
    "## 2) L√†m s·∫°ch d·ªØ li·ªáu nhanh\n",
    "- Chu·∫©n h√≥a c·ªôt `sex/gender` (n·∫øu c√≥) ‚Üí th√™m c·ªôt nh·ªã ph√¢n `*_num`.\n",
    "- Chuy·ªÉn c√°c c·ªôt object c√≥ d·∫°ng s·ªë (\"1,200\", \"45%\") th√†nh s·ªë `_num`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5106b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.copy()\n",
    "\n",
    "# Chu·∫©n h√≥a sex/gender (n·∫øu c√≥)\n",
    "for col in df.columns:\n",
    "    if str(col).strip().lower() in (\"sex\", \"gender\"):\n",
    "        df[col] = df[col].astype(str).str.strip().str.upper()\n",
    "        mapping = {\"M\":1, \"MALE\":1, \"NAM\":1, \"F\":0, \"FEMALE\":0, \"NU\":0, \"N·ªÆ\":0}\n",
    "        df[col + \"_num\"] = df[col].map(mapping)\n",
    "\n",
    "def to_numeric_series(s: pd.Series) -> pd.Series:\n",
    "    return (\n",
    "        s.astype(str)\n",
    "         .str.replace(\",\", \"\", regex=False)\n",
    "         .str.replace(\"%\", \"\", regex=False)\n",
    "         .str.replace(r\"[^\\d\\.\\-\\+eE]\", \"\", regex=True)\n",
    "         .str.strip()\n",
    "         .pipe(pd.to_numeric, errors=\"coerce\")\n",
    "    )\n",
    "\n",
    "df_num = df.select_dtypes(include=\"number\").copy()\n",
    "for c in df.select_dtypes(include=\"object\").columns:\n",
    "    cand = to_numeric_series(df[c])\n",
    "    if cand.notna().sum() >= max(3, int(0.5*len(df))):\n",
    "        df_num[c + \"_num\"] = cand\n",
    "\n",
    "print(\"Numeric columns considered:\")\n",
    "print(df_num.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276a069a",
   "metadata": {},
   "source": [
    "\n",
    "## 3) ƒê·∫∑c tr∆∞ng th·ªëng k√™\n",
    "- T√≠nh: `mean`, `median`, `std`, `min`, `max`, `count`\n",
    "- In `describe()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e609aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"--- STATS ---\")\n",
    "stats_df = pd.DataFrame({\n",
    "    \"mean\": df_num.mean(numeric_only=True),\n",
    "    \"median\": df_num.median(numeric_only=True),\n",
    "    \"std\": df_num.std(numeric_only=True),\n",
    "    \"min\": df_num.min(numeric_only=True),\n",
    "    \"max\": df_num.max(numeric_only=True),\n",
    "    \"count\": df_num.count()\n",
    "})\n",
    "display(stats_df)\n",
    "\n",
    "print(\"\\n--- DESCRIBE ---\")\n",
    "display(df_num.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9421927",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Tr·ª±c quan h√≥a\n",
    "- V·∫Ω **1 histogram** cho c·ªôt s·ªë ƒë·∫ßu ti√™n\n",
    "- V·∫Ω **1 boxplot** cho t·ªëi ƒëa 10 c·ªôt s·ªë ƒë·∫ßu ti√™n\n",
    "- V·∫Ω **1 scatter** cho 2 c·ªôt s·ªë ƒë·∫ßu ti√™n (n·∫øu c√≥)\n",
    "- V·∫Ω **heatmap t∆∞∆°ng quan** (d√πng `imshow`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5067aed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_cols = df_num.columns.tolist()\n",
    "\n",
    "# Histogram\n",
    "if len(num_cols) >= 1:\n",
    "    col = num_cols[0]\n",
    "    plt.figure()\n",
    "    plt.hist(df_num[col].dropna(), bins=20)\n",
    "    plt.title(f\"Histogram: {col}\")\n",
    "    plt.xlabel(col); plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "# Boxplot\n",
    "cols = num_cols[:10]\n",
    "if len(cols) >= 1:\n",
    "    plt.figure(figsize=(max(6, 0.6*len(cols)), 4))\n",
    "    plt.boxplot([df_num[c].dropna() for c in cols], labels=cols, vert=True)\n",
    "    plt.title(\"Boxplot (first numeric columns)\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Scatter\n",
    "if len(num_cols) >= 2:\n",
    "    xcol, ycol = num_cols[0], num_cols[1]\n",
    "    plt.figure()\n",
    "    plt.scatter(df_num[xcol], df_num[ycol])\n",
    "    plt.title(f\"Scatter: {xcol} vs {ycol}\")\n",
    "    plt.xlabel(xcol); plt.ylabel(ycol)\n",
    "    plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "if len(num_cols) >= 2:\n",
    "    corr = df_num.corr(numeric_only=True)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.imshow(corr, aspect=\"auto\")\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Correlation heatmap\")\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "    plt.yticks(range(len(corr.index)), corr.index)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85baaab",
   "metadata": {},
   "source": [
    "\n",
    "## 5) B√†i t·∫≠p theo c·ªôt ƒë·∫∑c th√π (n·∫øu t·ªìn t·∫°i)\n",
    "- N·∫øu c√≥ `BMIAP` v√† `BMISP`: ƒë·∫øm t·ª∑ l·ªá BMI gi·∫£m (BMIAP < BMISP) v√† kho·∫£ng tin c·∫≠y 90% cho t·ª∑ l·ªá.\n",
    "- N·∫øu c√≥ `SEX`/`GENDER`: t√≠nh trung b√¨nh 1 bi·∫øn theo gi·ªõi.\n",
    "- N·∫øu c√≥ `height` (inch) v√† `weight` (pound): ƒë·ªïi ƒë∆°n v·ªã v√† t√≠nh BMI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e45ad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# BMI decrease & 90% CI\n",
    "if set([\"BMIAP\",\"BMISP\"]).issubset(df.columns):\n",
    "    n = len(df)\n",
    "    x = (df[\"BMIAP\"] < df[\"BMISP\"]).sum()\n",
    "    p_hat = x / n if n else np.nan\n",
    "    z = 1.645\n",
    "    se = math.sqrt(p_hat*(1-p_hat)/n) if n else np.nan\n",
    "    lo = p_hat - z*se\n",
    "    hi = p_hat + z*se\n",
    "    print(f\"[BMI decrease] {x}/{n} -> pÃÇ={p_hat:.3f}, 90% CI=({lo:.3f}, {hi:.3f})\")\n",
    "\n",
    "# Group mean by SEX/GENDER for first numeric column\n",
    "sexcol = None\n",
    "for c in df.columns:\n",
    "    if str(c).strip().lower() in (\"sex\",\"gender\"):\n",
    "        sexcol = c\n",
    "        break\n",
    "\n",
    "if sexcol and len(df_num.columns) >= 1:\n",
    "    gmean = df.groupby(sexcol)[df_num.columns[0]].mean(numeric_only=True)\n",
    "    print(f\"Group mean by {sexcol} for {df_num.columns[0]}:\")\n",
    "    print(gmean)\n",
    "\n",
    "# Height/Weight convert + BMI\n",
    "hcol_candidates = [c for c in df.columns if str(c).lower().startswith(\"height\")]\n",
    "wcol_candidates = [c for c in df.columns if str(c).lower().startswith(\"weight\")]\n",
    "if hcol_candidates and wcol_candidates:\n",
    "    hcol, wcol = hcol_candidates[0], wcol_candidates[0]\n",
    "    # Th·ª≠ ƒëo√°n inch->cm, pound->kg (n·∫øu d·ªØ li·ªáu h·ª£p l√Ω)\n",
    "    h_cm = df[hcol]*2.54\n",
    "    w_kg = df[wcol]*0.453592\n",
    "    bmi = w_kg / ((h_cm/100.0)**2)\n",
    "    print(f\"BMI preview (using {hcol},{wcol}):\")\n",
    "    display(bmi.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc75c535",
   "metadata": {},
   "source": [
    "\n",
    "# Ph·∫ßn B ‚Äî X√°c su·∫•t & Ph√¢n v·ªã\n",
    "\n",
    "Cho bi·∫øt v√† √°p d·ª•ng 3 ph√¢n ph·ªëi: **Binomial**, **Poisson**, **Normal**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f5f4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from math import comb\n",
    "from scipy.stats import binom, poisson, norm\n",
    "\n",
    "# --- Binomial ---\n",
    "# TODO: ƒëi·ªÅn n, p, k ph√π h·ª£p ƒë·ªÅ\n",
    "n, p, k = 10, 0.3, 3\n",
    "P_eq = binom.pmf(k, n, p)         # P(X = k)\n",
    "P_le = binom.cdf(k, n, p)         # P(X <= k)\n",
    "k90 = binom.ppf(0.90, n, p)       # 90th percentile\n",
    "print(\"[Binomial] P(X=k)=\", P_eq, \"  P(X<=k)=\", P_le, \"  k_90=\", k90)\n",
    "\n",
    "# --- Poisson ---\n",
    "lam = 6\n",
    "P2 = poisson.pmf(2, lam)\n",
    "P_ge_3 = 1 - poisson.cdf(2, lam)  # P(X >= 3)\n",
    "x95_pois = poisson.ppf(0.95, lam)\n",
    "print(\"[Poisson] P(X=2)=\", P2, \"  P(X>=3)=\", P_ge_3, \"  x_95%=\", x95_pois)\n",
    "\n",
    "# --- Normal ---\n",
    "mu, sigma = 100, 15\n",
    "P_less_120 = norm.cdf(120, mu, sigma)\n",
    "P_between = norm.cdf(115, mu, sigma) - norm.cdf(85, mu, sigma)\n",
    "x90 = norm.ppf(0.90, mu, sigma)\n",
    "print(\"[Normal] P(X<120)=\", P_less_120, \"  P(85<X<115)=\", P_between, \"  x_90%=\", x90)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3b17cd",
   "metadata": {},
   "source": [
    "\n",
    "## Kho·∫£ng tin c·∫≠y cho **t·ª∑ l·ªá** (one-sample, normal approx)\n",
    "C√¥ng th·ª©c 90% CI cho t·ª∑ l·ªá \\(p\\) v·ªõi m·∫´u \\(n\\), t·∫ßn s·ªë \\(x\\), \\(\\hat p = x/n\\):\n",
    "\\[\n",
    "\\hat p \\pm z_{0.05}\\sqrt{\\hat p(1-\\hat p)/n},\\quad z_{0.05}=1.645\n",
    "\\]\n",
    "ƒêi·ªÅn s·ªë th·ª±c t·∫ø c·ªßa b·∫°n:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b17169",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: thay x, n b·∫±ng d·ªØ li·ªáu c·ªßa b·∫°n\n",
    "x, n = 6, 15\n",
    "p_hat = x/n\n",
    "z = 1.645\n",
    "se = math.sqrt(p_hat*(1-p_hat)/n)\n",
    "lo, hi = p_hat - z*se, p_hat + z*se\n",
    "print(f\"pÃÇ={p_hat:.3f}, 90% CI=({lo:.3f}, {hi:.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ecf9f9",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**K·∫øt th√∫c b√†i luy·ªán.**  \n",
    "B·∫°n c√≥ th·ªÉ ƒë·ªïi `DATA_PATH` ƒë·ªÉ luy·ªán v·ªõi c√°c dataset kh√°c nhau v√† l·∫∑p l·∫°i c√°c b∆∞·ªõc.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
